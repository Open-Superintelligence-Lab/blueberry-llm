# Contributing to Blueberry LLM ü´ê

## Quick Start
1. Fork the repo
2. Make your changes
3. Test: `python train_auto.py`
4. Submit a Pull Request (PR)

## What We Want
- **Performance**: Faster training, lower memory, better scaling
- **Research**: MoE experiments, routing improvements, optimizations
- **UX**: Better auto-config, CLI options

## Guidelines
- Keep it simple - anyone should be able to run your changes
- Test on at least 1 GPU setup, possibly 2x free GPU on Kaggle

## Research Ideas
- Different expert counts/dimensions
- Activation functions (SwiGLU, GEGLU, etc.)
- Routing strategies (capacity, load balancing)
- Batch scheduling optimizations
- Distributed training improvements

## Questions?
Open an issue or start a discussion!
