[
  {
    "val_loss": 7.220436134338379,
    "val_accuracy": 0.155498046875,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.032632104555766,
    "steps_per_second": 2.4138935298531763,
    "mfu": 0.0033786637729435716,
    "training_time_minutes": 2.0801225503285727,
    "training_time_hours": 0.03452237321270837,
    "final_step": 300,
    "best_val_loss": 7.09591079711914,
    "experiment_name": "Baseline",
    "description": "Original 490 Max configuration (adapted to 512)",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.219631271362305,
    "val_accuracy": 0.1631640625,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.9992071946461993,
    "steps_per_second": 1.6366793108777757,
    "mfu": 0.002632612549261692,
    "training_time_minutes": 3.059775153795878,
    "training_time_hours": 0.050916103588210214,
    "final_step": 300,
    "best_val_loss": 7.072995929718018,
    "experiment_name": "Deeper",
    "description": "12 layers instead of 8, adjusted dimensions",
    "config_summary": {
      "d_model": 448,
      "n_layers": 12,
      "n_heads": 14,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.434160861968994,
    "val_accuracy": 0.150322265625,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.0588323791821797,
    "steps_per_second": 2.3836785615982405,
    "mfu": 0.0052038677623720275,
    "training_time_minutes": 2.1034788886706033,
    "training_time_hours": 0.034959970977571274,
    "final_step": 300,
    "best_val_loss": 7.0580988693237305,
    "experiment_name": "Wider",
    "description": "640 dimensions instead of 512, more attention heads",
    "config_summary": {
      "d_model": 640,
      "n_layers": 8,
      "n_heads": 20,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.221039562225342,
    "val_accuracy": 0.156953125,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.952562125523885,
    "steps_per_second": 1.6611919515694378,
    "mfu": 0.003445213891113595,
    "training_time_minutes": 3.0147374908129376,
    "training_time_hours": 0.050164782736036514,
    "final_step": 300,
    "best_val_loss": 7.093723163604737,
    "experiment_name": "MoreExperts",
    "description": "24 experts instead of 16",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 24,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.259630832672119,
    "val_accuracy": 0.159990234375,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.03296377658844,
    "steps_per_second": 2.413619103409175,
    "mfu": 0.0033781125539330803,
    "training_time_minutes": 2.0747369527816772,
    "training_time_hours": 0.03452629837724898,
    "final_step": 300,
    "best_val_loss": 7.084872856140136,
    "experiment_name": "Top3Experts",
    "description": "Top-3 expert selection instead of top-2",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 3,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.265383110046387,
    "val_accuracy": 0.16173828125,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.0601996501286823,
    "steps_per_second": 2.380715625834027,
    "mfu": 0.003333453849948794,
    "training_time_minutes": 2.1034130414326984,
    "training_time_hours": 0.03500348064634535,
    "final_step": 300,
    "best_val_loss": 7.082851104736328,
    "experiment_name": "LowDropout",
    "description": "0.05 dropout instead of 0.1",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.05,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.527327175140381,
    "val_accuracy": 0.16056640625,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 102400,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.0439343730608623,
    "steps_per_second": 2.400986222053242,
    "mfu": 0.0033599809005120727,
    "training_time_minutes": 2.0856430570284528,
    "training_time_hours": 0.03470795982413822,
    "final_step": 300,
    "best_val_loss": 7.07665756225586,
    "experiment_name": "HighLR",
    "description": "0.015 learning rate instead of 0.01",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.015,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 6.7802790260314945,
    "val_accuracy": 0.160234375,
    "val_perplexity": 880.3143204536265,
    "total_tokens": 51200,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 1.714426859219869,
    "steps_per_second": 2.851518623768217,
    "mfu": 0.004005758786647587,
    "training_time_minutes": 1.7565890312194825,
    "training_time_hours": 0.029224193957116867,
    "final_step": 300,
    "best_val_loss": 6.7802790260314945,
    "experiment_name": "SmallBatch",
    "description": "Batch size 8 with more accumulation",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 8,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 256
    }
  },
  {
    "val_loss": 7.551146443684896,
    "val_accuracy": 0.15067057291666666,
    "val_perplexity": 999.9999999999998,
    "total_tokens": 153600,
    "num_steps": 25,
    "step": 300,
    "elapsed_time_minutes": 2.1302890221277875,
    "steps_per_second": 2.3017369938333045,
    "mfu": 0.0048538424730071,
    "training_time_minutes": 2.1754377484321594,
    "training_time_hours": 0.03620454185538822,
    "final_step": 300,
    "best_val_loss": 7.27096674601237,
    "experiment_name": "LongSeq",
    "description": "384 sequence length instead of 256",
    "config_summary": {
      "d_model": 512,
      "n_layers": 8,
      "n_heads": 16,
      "num_experts": 16,
      "expert_top_k": 2,
      "batch_size": 16,
      "muon_lr": 0.01,
      "dropout": 0.1,
      "max_seq_len": 384
    }
  }
]