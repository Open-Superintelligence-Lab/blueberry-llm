# MoE Ablation - Simple Workflow âš¡

## ğŸ¯ Quick Start (3 Steps)

### 1. Edit your config
Open `configs_ablation.py` and modify:
```python
CUSTOM = AblationConfig(
    name="custom",
    batch_size=32,      # â† Edit this
    seq_len=384,        # â† Edit this
    lr=0.015,
    grad_accum=2,
    max_steps=50
)
```

### 2. Run it
```bash
python run_ablation.py custom
```

### 3. See results
Output shows:
- âœ… Val Loss & Accuracy
- ğŸš€ Throughput (tokens/sec)
- ğŸ’¾ **Peak Memory** (to max out GPU)

---

## ğŸ“Š Plot All Results
```bash
python plot_results.py
```
Saves to `results/ablation_batch_seqlen/ablation_results.png`

---

## ğŸ”§ Finding Your Max Memory Config

**Goal:** Max out your GPU memory for best throughput

**Method:**
1. Start: `python run_ablation.py quick`
2. Edit `configs_ablation.py` â†’ increase `batch_size` or `seq_len`
3. Run: `python run_ablation.py custom`
4. Check **Peak Memory** in output
5. Repeat until OOM error â†’ back off 10-20%

**Example progression:**
```python
# Try 1: batch=32, seqlen=384 â†’ Peak: 8GB âœ…
# Try 2: batch=64, seqlen=384 â†’ Peak: 14GB âœ…
# Try 3: batch=96, seqlen=384 â†’ Peak: 21GB âœ…
# Try 4: batch=128, seqlen=384 â†’ OOM! âŒ
# Final: batch=96, seqlen=384 â†’ Perfect! ğŸ¯
```

---

## ğŸ“‹ Pre-made Configs

```bash
python run_ablation.py quick        # Fast test (5 steps)
python run_ablation.py large_batch  # Max batch (64Ã—256)
python run_ablation.py long_seq     # Max seqlen (8Ã—1024)
python run_ablation.py balanced     # Balanced (24Ã—512)
python run_ablation.py max_batch    # Aggressive batch (128Ã—128)
python run_ablation.py max_seq      # Aggressive seqlen (4Ã—2048)
```

---

## ğŸ” Understanding Output

```
âœ… RESULTS: custom
   Val Loss: 7.7533       â† Lower is better
   Val Acc: 9.23%         â† Higher is better  
   Throughput: 36,132 tok/s  â† Higher is better
   Peak Memory: 8.45 GB   â† Use this to tune batch/seqlen
```

**Memory ~= batch_size Ã— seq_len Ã— model_params**

If Peak Memory < GPU Memory â†’ increase batch or seqlen!

---

## ğŸ¯ Tips

- **More batch** = better throughput, same learning
- **More seqlen** = better long-range context
- **Grad accum** = larger effective batch without more memory
- Start with `quick`, iterate fast

---

That's it! Edit config â†’ Run â†’ Check memory â†’ Repeat ğŸš€

